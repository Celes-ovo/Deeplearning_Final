{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "McQLZea8yHFu"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob, os\n",
        "import natsort\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras import models, layers\n",
        "\n",
        "\n",
        "np.random.seed(77)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdiPlxm5yHDT",
        "outputId": "20d05537-f0a3-4def-ffd8-0cdf2daf5485"
      },
      "source": [
        "# to get the files in proper order\n",
        "def sorted_alphanumeric(data):  \n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
        "    return sorted(data,key = alphanum_key)\n",
        "# defining the size of the image\n",
        "SIZE = 100\n",
        "high_img = []\n",
        "path = '/content/drive/MyDrive/GAN/Super_resolution/Raw Data/high_res'\n",
        "files = os.listdir(path)\n",
        "files = sorted_alphanumeric(files)\n",
        "for i in tqdm(files):    \n",
        "    if i == '855.jpg':\n",
        "        break\n",
        "    else:    \n",
        "        img = cv2.imread(path + '/'+i,1)\n",
        "        # open cv reads images in BGR format so we have to convert it to RGB\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        #resizing image\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = img.astype('float32') / 255.0\n",
        "\n",
        "        high_img.append(img_to_array(img))\n",
        "\n",
        "\n",
        "low_img = []\n",
        "path = '/content/drive/MyDrive/GAN/Super_resolution/Raw Data/low_res'\n",
        "files = os.listdir(path)\n",
        "files = sorted_alphanumeric(files)\n",
        "for i in tqdm(files):\n",
        "     if i == '855.jpg':\n",
        "        break\n",
        "     else: \n",
        "        img = cv2.imread(path + '/'+i,1)\n",
        "\n",
        "        #resizing image\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = img.astype('float32') / 255.0\n",
        "\n",
        "        low_img.append(img_to_array(img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 855/855 [00:06<00:00, 142.39it/s]\n",
            "100%|██████████| 855/855 [00:05<00:00, 150.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nT2f-iPyHAZ"
      },
      "source": [
        "from tensorflow.keras import losses, metrics, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# high_img, low_img\n",
        "x_train, x_test, y_train, y_test = train_test_split(low_img, high_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k84rFQyUyG9Q"
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHlhH88AyG62",
        "outputId": "9237df2a-6c42-4c05-ddda-6c811791618d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(641, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekywt1pfyBBl"
      },
      "source": [
        "def create_generator():\n",
        "    generator=models.Sequential()\n",
        "    generator.add(layers.Dense(units=256,input_dim=10000))\n",
        "    generator.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(layers.Dense(units=512))\n",
        "    generator.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(layers.Dense(units=1024))\n",
        "    generator.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(layers.Dense(units=10000, activation='tanh'))\n",
        "    \n",
        "    generator.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxcHHqCayC5v"
      },
      "source": [
        "def create_discriminator():\n",
        "    discriminator=models.Sequential()\n",
        "    discriminator.add(layers.Dense(units=1024,input_dim=10000))\n",
        "    discriminator.add(layers.LeakyReLU(0.2))\n",
        "    discriminator.add(layers.Dropout(0.3))\n",
        "    \n",
        "    discriminator.add(layers.Dense(units=512))\n",
        "    discriminator.add(layers.LeakyReLU(0.2))\n",
        "    discriminator.add(layers.Dropout(0.3))\n",
        "       \n",
        "    discriminator.add(layers.Dense(units=256))\n",
        "    discriminator.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(layers.Dense(units=3, activation='sigmoid'))\n",
        "    \n",
        "    discriminator.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tUJd5akyDg9"
      },
      "source": [
        "def create_gan(discriminator, generator):\n",
        "    discriminator.trainable=False\n",
        "    gan_input = models.Input(shape=10000)\n",
        "    x = generator(gan_input)\n",
        "    gan_output= discriminator(x)\n",
        "    gan= keras.models.Model(inputs=gan_input, outputs=gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return gan\n",
        "\n",
        "def plot_generated_images(epoch, generator, examples=100, dim=(10,10), figsize=(10,10)):\n",
        "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(100,256,256)\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gan_generated_image %d.png' %epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpC_GSRM9oGv",
        "outputId": "05c0e6c4-2cbe-4dba-8084-bd40a8a22f3c"
      },
      "source": [
        "image_batch =x_train[np.random.randint(low=0,high=256,size=30)]\n",
        "print(image_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ySYRn__Xx5_H",
        "outputId": "c4e7743d-35d0-4757-eb85-93b70562f87f"
      },
      "source": [
        "def training(epochs=1, batch_size=128):\n",
        "\n",
        "    batch_count = x_train.shape[0] // batch_size\n",
        "    print(batch_count)\n",
        "    \n",
        "    # Creating GAN\n",
        "    generator = create_generator()\n",
        "    discriminator = create_discriminator()\n",
        "    gan = create_gan(discriminator, generator)\n",
        "    \n",
        "    \"\"\"## structure of model\n",
        "    from keras.utils import plot_model\n",
        "    plot_model(generator, show_shapes=True, to_file='generator.png')\n",
        "    \n",
        "    plot_model(discriminator, show_shapes=True, to_file='discriminator.png')\n",
        "    \n",
        "    plot_model(gan, show_shapes=True, to_file='gan.png')\"\"\"\n",
        "    \n",
        "    for e in range(1,epochs+1):\n",
        "        print(\"Epoch %d\" %e)\n",
        "        for _ in tqdm(range(batch_size)):\n",
        "        # Generate random noise as an input to initialize the generator\n",
        "            noise= np.random.normal(0, 1, [batch_size, 10000])\n",
        "            \n",
        "            # Generate fake MNIST images from noised input\n",
        "            generated_images = generator.predict(noise)\n",
        "            print(generated_images.shape)\n",
        "            \n",
        "            # Get a random set of  real images\n",
        "            image_batch =x_train[np.random.randint(low=0,high=256,size=batch_size)]\n",
        "            print(image_batch.shape)\n",
        "            \n",
        "            # Construct different batches of real and fake data\n",
        "            X= np.concatenate([image_batch, generated_images])\n",
        "            \n",
        "            # Labels for generated and real data\n",
        "            y_dis=np.zeros(2*batch_size)\n",
        "            y_dis[:batch_size]=0.9\n",
        "            \n",
        "            # Pretrain discriminator on  fake and real data before starting the gan. \n",
        "            discriminator.trainable=True\n",
        "            discriminator.train_on_batch(X, y_dis)\n",
        "            \n",
        "            # Tricking the noised input of the Generator as real data\n",
        "            y_gen = np.ones(batch_size)\n",
        "            \n",
        "            # During the training of gan, the weights of discriminator should be fixed. \n",
        "            # We can enforce that by setting the trainable flag\n",
        "            discriminator.trainable=False\n",
        "            \n",
        "            # Training  the GAN by alternating the training of the Discriminator and training the chained GAN model with Discriminator's weights freezed.\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "            \n",
        "        if e == 1 or e % 20 == 0:\n",
        "           plot_generated_images(e, generator)\n",
        "\n",
        "training(400,128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/128 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 10000)\n",
            "(128, 100, 100, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-2b9a083c3b05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m            \u001b[0mplot_generated_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-2b9a083c3b05>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Construct different batches of real and fake data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Labels for generated and real data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 1 has 2 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbDyyuJs2Jjf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}